p8105\_hw5\_WZ2591
================
Wenyu Zhang
11/15/2021

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   2.0.1     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(rvest)
```

    ## 
    ## Attaching package: 'rvest'

    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

## import and clean data

``` r
homicide_df = 
  read_csv("data-homicides-master/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = ",", collapse = NULL), 
    resolved_cases = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved")
    ) %>% 
  filter(city_state != "Tulsa,AL") %>% 
  select(city_state, resolved_cases)
```

    ## Rows: 52179 Columns: 12

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
homicide_df
```

    ## # A tibble: 52,178 × 2
    ##    city_state     resolved_cases
    ##    <chr>          <chr>         
    ##  1 Albuquerque,NM unsolved      
    ##  2 Albuquerque,NM solved        
    ##  3 Albuquerque,NM unsolved      
    ##  4 Albuquerque,NM solved        
    ##  5 Albuquerque,NM unsolved      
    ##  6 Albuquerque,NM unsolved      
    ##  7 Albuquerque,NM solved        
    ##  8 Albuquerque,NM solved        
    ##  9 Albuquerque,NM unsolved      
    ## 10 Albuquerque,NM unsolved      
    ## # … with 52,168 more rows

## summarize within cities to obtain the total number of homicides and the number of unsolved homicides

``` r
number_homicides_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    cases_total = n(),
    unsolved_cases_total = sum(resolved_cases == "unsolved")
  )

number_homicides_df
```

    ## # A tibble: 50 × 3
    ##    city_state     cases_total unsolved_cases_total
    ##    <chr>                <int>                <int>
    ##  1 Albuquerque,NM         378                  146
    ##  2 Atlanta,GA             973                  373
    ##  3 Baltimore,MD          2827                 1825
    ##  4 Baton Rouge,LA         424                  196
    ##  5 Birmingham,AL          800                  347
    ##  6 Boston,MA              614                  310
    ##  7 Buffalo,NY             521                  319
    ##  8 Charlotte,NC           687                  206
    ##  9 Chicago,IL            5535                 4073
    ## 10 Cincinnati,OH          694                  309
    ## # … with 40 more rows

## use prop.test function to estimate the proportion of homicides that are unsolved

``` r
prop.test(
  number_homicides_df %>% filter(city_state == "Baltimore,MD") %>% pull(unsolved_cases_total), 
  number_homicides_df %>% filter(city_state == "Baltimore,MD") %>% 
    pull(cases_total)
  ) %>% 
  broom::tidy()
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

## run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each.

``` r
results_df = 
  number_homicides_df %>% 
  mutate(
    prop_tests = map2(.x = unsolved_cases_total, .y = cases_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)

results_df
```

    ## # A tibble: 50 × 4
    ##    city_state     estimate conf.low conf.high
    ##    <chr>             <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque,NM    0.386    0.337     0.438
    ##  2 Atlanta,GA        0.383    0.353     0.415
    ##  3 Baltimore,MD      0.646    0.628     0.663
    ##  4 Baton Rouge,LA    0.462    0.414     0.511
    ##  5 Birmingham,AL     0.434    0.399     0.469
    ##  6 Boston,MA         0.505    0.465     0.545
    ##  7 Buffalo,NY        0.612    0.569     0.654
    ##  8 Charlotte,NC      0.300    0.266     0.336
    ##  9 Chicago,IL        0.736    0.724     0.747
    ## 10 Cincinnati,OH     0.445    0.408     0.483
    ## # … with 40 more rows

``` r
results_df_plot = 
  results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

results_df_plot
```

<img src="p8105_hw5_WZ2591_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

# Probelm 2

``` r
data_df = 
  tibble(
    file_name = list.files("lda-data")
  ) %>% 
  mutate(
    path = str_c("lda-data/", file_name),
    data = map(path, read_csv)
  )
```

## 1. Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time

``` r
lda_tidy_df = 
  data_df %>% 
  unnest(data) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation_values") %>% 
  separate(file_name, into = c("arm", "subject_ID"), sep = "_") %>% 
  mutate(
    arm = str_replace(arm, "con", "Control"),
    arm = str_replace(arm, "exp", "Experimental"),
    subject_ID = str_replace(subject_ID, ".csv", ""),
    week = str_replace(week, "week_", "")) %>% 
  mutate(arm = as.factor(arm)) %>% 
  select(-path)
```

## 2. Tidy the result; manipulate file names to include control arm and subject ID

``` r
lda_control_df = 
  lda_tidy_df %>%
  filter(arm == "Control")
```

## 3. Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

``` r
lda_tidy_plot = 
  lda_tidy_df %>% 
  ggplot(aes(x = week, 
             y = observation_values , 
             group = subject_ID, 
             color = subject_ID)) +
  geom_line() +
  facet_grid(. ~ arm) +
  labs(
    title = "observations of control group and experimental group over time",
    x = "Weeks",
    y = "Observation values",
    caption = "the data was loaded from longitudinal study"
  ) + 
  scale_color_hue(name = "subject_ID", h = c(10, 300))

lda_tidy_plot  
```

<img src="p8105_hw5_WZ2591_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

Based on the graphs above, the experimental graph shows that values
positively increase as the week increases. The control group shows that
there is no obviously relationship between observation values and week
date because values show random change over weeks
